{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoK7NEtEYHrD",
        "outputId": "369ef80b-1892-4de9-f944-aced309cac37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines) (25.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from bert-score) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.12/dist-packages (from bert-score) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bert-score) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score) (3.2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.3.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->bert-score) (2025.11.12)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=835dff971b976f7e55ad6636159a9bf3ef3a0e9267a2a9a83d3e6b2668a74623\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: jsonlines, rouge-score, bert-score\n",
            "Successfully installed bert-score-0.3.13 jsonlines-4.0.0 rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "# Install libraries for metrics and data handling\n",
        "%pip install pandas scikit-learn jsonlines rouge-score bert-score transformers torch\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import torch\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Regular Expressions for Parsing Generated Text ---\n",
        "\n",
        "# Pattern to capture the caption text\n",
        "CAPTION_RE = re.compile(\n",
        "    r\"Caption:\\s*(.*?)\\s*(?:\\\\nConcept descriptions:|\\\\nConcepts:|$)\",\n",
        "    flags=re.S\n",
        ")\n",
        "\n",
        "# Pattern to capture the raw concepts list\n",
        "CONCEPTS_RE = re.compile(\n",
        "    r\"Concepts:\\s*(.*)\\s*$\",\n",
        "    flags=re.S\n",
        ")\n",
        "\n",
        "def extract_caption_and_concepts(text: str) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Parses the model's single-string output to extract the structured caption and concepts.\n",
        "    \"\"\"\n",
        "    text = (text or \"\").strip()\n",
        "\n",
        "    # 1. Extract Caption (Primary target)\n",
        "    m_cap = CAPTION_RE.search(text)\n",
        "    # Clean up the generation, removing the end-of-turn token if present\n",
        "    caption = m_cap.group(1).strip().replace('<end_of_turn>', '').strip() if m_cap else \"\"\n",
        "\n",
        "    # 2. Extract Concepts (Secondary target)\n",
        "    m_con = CONCEPTS_RE.search(text)\n",
        "    concepts_str = m_con.group(1).strip().replace('<end_of_turn>', '').strip() if m_con else \"\"\n",
        "\n",
        "    # 3. Split raw string into a list of cleaned CUIs\n",
        "    concepts = [c.strip() for c in concepts_str.split(\",\") if c.strip()] if concepts_str else []\n",
        "\n",
        "    return pd.Series({\"caption_extracted\": caption, \"concepts_extracted\": concepts})"
      ],
      "metadata": {
        "id": "dnRoaZ76YK04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ROUGE Scorer outside the loop for efficiency\n",
        "ROUGE_SCORER = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "\n",
        "# Initialize BERT Scorer outside the loop for efficiency\n",
        "# NOTE: Requires a GPU for fast execution and downloads the BERT model upon first call.\n",
        "# Using 'bert-base-uncased' as a common default.\n",
        "BERT_SCORER = score\n",
        "\n",
        "def calculate_rouge_1_f1(reference: str, candidate: str) -> float:\n",
        "    \"\"\"Calculates the ROUGE-1 F1 score.\"\"\"\n",
        "    if not reference or not candidate:\n",
        "        return 0.0\n",
        "\n",
        "    # ROUGE scorer handles tokenization internally\n",
        "    scores = ROUGE_SCORER.score(reference, candidate)\n",
        "    return scores['rouge1'].fmeasure\n",
        "\n",
        "def calculate_bertscore_f1(references: list[str], candidates: list[str]) -> float:\n",
        "    \"\"\"Calculates the average BERTScore F1 across the corpus.\"\"\"\n",
        "    if not references or not candidates:\n",
        "        return 0.0\n",
        "\n",
        "    # P, R, F1 are tensors; we need the mean of the F1 tensor\n",
        "    # lang='en' is appropriate for the ROCO dataset captions.\n",
        "    P, R, F1 = BERT_SCORER(candidates, references, lang=\"en\", verbose=False)\n",
        "    return F1.mean().item()\n",
        "\n",
        "\n",
        "def calculate_concept_metrics(df: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Calculates overall Micro F1 (Primary) and Macro F1 (Secondary) for concept extraction.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Identify all unique concepts across all actual and predicted lists\n",
        "    all_actuals = set(c for sublist in df['cui'] for c in sublist if isinstance(c, str))\n",
        "    all_predicted = set(c for sublist in df['concepts_extracted'] for c in sublist if isinstance(c, str))\n",
        "\n",
        "    all_unique_concepts = sorted(list(all_actuals.union(all_predicted)))\n",
        "\n",
        "    if not all_unique_concepts:\n",
        "        return pd.Series({\n",
        "            'Concept_F1_Micro': 0.0,\n",
        "            'Concept_F1_Macro': 0.0\n",
        "        })\n",
        "\n",
        "    # 2. Create binary presence vectors (y_true and y_pred)\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        actual_concepts = set(c for c in row['cui'] if isinstance(c, str))\n",
        "        predicted_concepts = set(c for c in row['concepts_extracted'] for c in sublist if isinstance(c, str))\n",
        "\n",
        "        y_true.append([1 if c in actual_concepts else 0 for c in all_unique_concepts])\n",
        "        y_pred.append([1 if c in predicted_concepts else 0 for c in all_unique_concepts])\n",
        "\n",
        "    # 3. Calculate metrics using scikit-learn\n",
        "    # F1 (Primary): Micro-averaged F1 (focuses on overall agreement, common for multi-label)\n",
        "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='micro', zero_division=0\n",
        "    )\n",
        "\n",
        "    # F1 Secondary: Macro-averaged F1 (focuses on per-concept accuracy, then averages)\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    return pd.Series({\n",
        "        'Concept_F1_Primary (Micro)': f1_micro,\n",
        "        'Concept_F1_Secondary (Macro)': f1_macro\n",
        "    })"
      ],
      "metadata": {
        "id": "Lss3Z-gFYM7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_evaluation(file_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Loads results from a JSONL file, computes all requested metrics, and prints the final report.\n",
        "    \"\"\"\n",
        "    print(f\"--- Starting Evaluation for: {file_path} ---\")\n",
        "\n",
        "    # Load data from JSONL\n",
        "    try:\n",
        "        results_df = pd.read_json(file_path, lines=True)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR: Could not load JSONL file. Please check path and format.\")\n",
        "        print(f\"Details: {e}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Loaded {len(results_df)} samples.\")\n",
        "\n",
        "    # Data Preprocessing: Parse the generated text\n",
        "    print(\"\\nParsing generated text to extract captions and concepts...\")\n",
        "    results_df[['caption_extracted', 'concepts_extracted']] = results_df['generation'].apply(extract_caption_and_concepts)\n",
        "\n",
        "    # 1. Calculate Caption Generation Metrics\n",
        "\n",
        "    # ROUGE-1 F1\n",
        "    print(\"Calculating ROUGE-1 F1...\")\n",
        "    results_df['rouge1_f1'] = results_df.apply(\n",
        "        lambda row: calculate_rouge_1_f1(row['caption'], row['caption_extracted']),\n",
        "        axis=1\n",
        "    )\n",
        "    average_rouge1_f1 = results_df['rouge1_f1'].mean()\n",
        "\n",
        "    # BERTScore F1\n",
        "    print(\"Calculating BERTScore F1 (may take a minute to load model)...\")\n",
        "    references = results_df['caption'].tolist()\n",
        "    candidates = results_df['caption_extracted'].tolist()\n",
        "\n",
        "    average_bertscore_f1 = calculate_bertscore_f1(references, candidates)\n",
        "\n",
        "    # 2. Calculate Concept Extraction Metrics\n",
        "    print(\"Calculating Concept F1 Metrics (Micro and Macro)...\")\n",
        "    concept_metrics = calculate_concept_metrics(results_df)\n",
        "\n",
        "    # --- Final Report ---\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"                MODEL PERFORMANCE EVALUATION REPORT\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\n[CAPTIONING METRICS]\")\n",
        "    print(f\"  > ROUGE-1 F1:     {average_rouge1_f1:.4f}\")\n",
        "    print(f\"  > BERTScore F1:   {average_bertscore_f1:.4f}\")\n",
        "\n",
        "    print(\"\\n[CONCEPT DETECTION METRICS]\")\n",
        "    print(f\"  > F1 (Primary / Micro):  {concept_metrics['Concept_F1_Primary (Micro)']:.4f}\")\n",
        "    print(f\"  > F1 (Secondary / Macro): {concept_metrics['Concept_F1_Secondary (Macro)']:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Evaluation Complete.\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Optional: Display a few sample rows with scores\n",
        "    print(\"\\nSample Predictions vs. Actuals:\")\n",
        "    print(results_df[['caption', 'caption_extracted', 'rouge1_f1']].head().to_markdown(index=False, numalign=\"left\"))\n",
        "\n",
        "\n",
        "# --- USER INPUT SECTION ---\n",
        "\n",
        "# TODO: Replace the placeholder path below with the actual path to your JSONL results file\n",
        "# generated by the scoring notebook (e.g., 'Score_Results/4Bit_Qunat_Gemma_...jsonl').\n",
        "\n",
        "# RESULTS_FILE_PATH = \"path/to/your/results.jsonl\"\n",
        "\n",
        "# To run the evaluation, uncomment the line below and replace with your file path:\n",
        "# run_evaluation(RESULTS_FILE_PATH)"
      ],
      "metadata": {
        "id": "FOrD9SWfYPcb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}