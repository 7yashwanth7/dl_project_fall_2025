{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install the requried packages"
      ],
      "metadata": {
        "id": "2wcwqDHA04WH"
      },
      "id": "2wcwqDHA04WH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pytorch & other libraries\n",
        "%pip install \"torch>=2.4.0\" tensorboard torchvision\n",
        "\n",
        "# Install Gemma release branch from Hugging Face\n",
        "%pip install \"transformers>=4.51.3\"\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "%pip install  --upgrade \\\n",
        "  \"datasets==3.3.2\" \\\n",
        "  \"accelerate==1.4.0\" \\\n",
        "  \"evaluate==0.4.3\" \\\n",
        "  \"bitsandbytes==0.45.3\" \\\n",
        "  \"trl==0.15.2\" \\\n",
        "  \"peft==0.14.0\" \\\n",
        "  \"pillow==11.1.0\" \\\n",
        "  protobuf \\\n",
        "  sentencepiece"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4MXBjs1dd12",
        "outputId": "7fbdacf9-a3dc-4807-db5f-6385a55a7af9"
      },
      "id": "a4MXBjs1dd12",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (6.33.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: transformers>=4.51.3 in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.51.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.51.3) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.51.3) (2025.11.12)\n",
            "Requirement already satisfied: datasets==3.3.2 in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: accelerate==1.4.0 in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: evaluate==0.4.3 in /usr/local/lib/python3.12/dist-packages (0.4.3)\n",
            "Requirement already satisfied: bitsandbytes==0.45.3 in /usr/local/lib/python3.12/dist-packages (0.45.3)\n",
            "Requirement already satisfied: trl==0.15.2 in /usr/local/lib/python3.12/dist-packages (0.15.2)\n",
            "Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: pillow==11.1.0 in /usr/local/lib/python3.12/dist-packages (11.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (6.33.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.3.2) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (3.13.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.3.2) (6.0.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.4.0) (0.7.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from trl==0.15.2) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.12/dist-packages (from trl==0.15.2) (4.57.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.3.2) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.3.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.3.2) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.3.2) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.4.0) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0->trl==0.15.2) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46.0->trl==0.15.2) (0.22.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.3.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.3.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.3.2) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->trl==0.15.2) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->trl==0.15.2) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.15.2) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.3.2) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.4.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.4.0) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the cluster to the google drive"
      ],
      "metadata": {
        "id": "jbwho5BC26Ff"
      },
      "id": "jbwho5BC26Ff"
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount the notebook on to the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set the working directory to dl_project_fall_2025\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/DL_Project_2025/dl_project_fall_2025\")\n",
        "\n",
        "# Auto relaod doesnt work in google colab, so you can use reload to reload your function calls\n",
        "from importlib import reload"
      ],
      "metadata": {
        "id": "ZD1bIPc-eOa3"
      },
      "id": "ZD1bIPc-eOa3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding PAT (Personal Access Tokens) to both Hugging Face and Google Drive"
      ],
      "metadata": {
        "id": "FYgnpney3U2b"
      },
      "id": "FYgnpney3U2b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84134828"
      },
      "source": [
        "# Importing git token and huggig face tokens\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Retrieve the GitHub Token from Colab secrets\n",
        "GH_TOKEN = userdata.get('git_token') # Ensure you stored your PAT under the secret name 'GH_TOKEN'\n",
        "hf_token = userdata.get('hugging_face')\n",
        "login(hf_token)\n",
        "\n",
        "# Configure Git to use the PAT directly in the remote URL for the 'origin'\n",
        "!git remote set-url origin https://{GH_TOKEN}@github.com/7yashwanth7/dl_project_fall_2025.git\n",
        "!git config --global user.email \"7yashwanth7@gmail.com\" # Modify to your username and pwd\n",
        "!git config --global user.name \"7yashwanth7\""
      ],
      "id": "84134828",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the functions"
      ],
      "metadata": {
        "id": "KcjebSqM3ge3"
      },
      "id": "KcjebSqM3ge3"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "\n",
        "from src.llmft.data_preprocessing import preprocess\n",
        "from src.llmft.data_preprocessing import preprocess_utils"
      ],
      "metadata": {
        "id": "iW7bJOq4EBPd",
        "collapsed": true
      },
      "id": "iW7bJOq4EBPd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "eLM3_lmDLnqZ",
        "outputId": "211845b0-7969-4f2b-8343-578956b91f68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eLM3_lmDLnqZ",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refresh index: 100% (35/35), done.\n",
            "On branch google_colab_development\n",
            "Your branch is up to date with 'origin/google_colab_development'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   src/llmft/__pycache__/__init__.cpython-312.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   src/llmft/data_preprocessing/__pycache__/__init__.cpython-312.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   src/llmft/data_preprocessing/__pycache__/preprocess.cpython-312.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   src/llmft/data_preprocessing/__pycache__/preprocess_utils.cpython-312.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   src/llmft/data_preprocessing/preprocess.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mgemma-3-cui-finetuned-sample1/\u001b[m\n",
            "\t\u001b[31mgemma-product-description/\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add src/llmft/data_preprocessing/preprocess.py"
      ],
      "metadata": {
        "id": "yvKhWOYVLqkG"
      },
      "id": "yvKhWOYVLqkG",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"added preprocessing of dataset\""
      ],
      "metadata": {
        "id": "yJ2CK5B8L_0A",
        "outputId": "48d68f35-c70b-4891-f28b-94afc7ec7290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yJ2CK5B8L_0A",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[google_colab_development 8da6669] added preprocessing of dataset\n",
            " 1 file changed, 51 insertions(+)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch origin\n",
        "!git pull --rebase origin google_colab_development\n",
        "!git push origin google_colab_development"
      ],
      "metadata": {
        "id": "d5NNGderMHXa",
        "outputId": "75f8f746-e217-4fff-9840-e7fd8aa2537d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d5NNGderMHXa",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects:  12% (1/8)\u001b[K\rremote: Compressing objects:  25% (2/8)\u001b[K\rremote: Compressing objects:  37% (3/8)\u001b[K\rremote: Compressing objects:  50% (4/8)\u001b[K\rremote: Compressing objects:  62% (5/8)\u001b[K\rremote: Compressing objects:  75% (6/8)\u001b[K\rremote: Compressing objects:  87% (7/8)\u001b[K\rremote: Compressing objects: 100% (8/8)\u001b[K\rremote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 8 (delta 4), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (8/8), 4.16 KiB | 13.00 KiB/s, done.\n",
            "From https://github.com/7yashwanth7/dl_project_fall_2025\n",
            "   ff5872d..43f65ca  google_colab_development -> origin/google_colab_development\n",
            "error: cannot pull with rebase: You have unstaged changes.\n",
            "error: please commit or stash them.\n",
            "To https://github.com/7yashwanth7/dl_project_fall_2025.git\n",
            " \u001b[31m! [rejected]       \u001b[m google_colab_development -> google_colab_development (non-fast-forward)\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/7yashwanth7/dl_project_fall_2025.git'\n",
            "\u001b[m\u001b[33mhint: Updates were rejected because the tip of your current branch is behind\u001b[m\n",
            "\u001b[33mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[m\n",
            "\u001b[33mhint: 'git pull ...') before pushing again.\u001b[m\n",
            "\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Models Configurations and Dataset"
      ],
      "metadata": {
        "id": "jxaT6uYl3kL7"
      },
      "id": "jxaT6uYl3kL7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model_config and json files\n",
        "defaults = preprocess_utils.read_yaml('src/llmft/config/defaults.yaml')\n",
        "cui_mapping_json = preprocess_utils.read_json('mapping_files/cui_mapping.json')\n",
        "cui_mapping = preprocess_utils.get_cui_mapping(cui_mapping_json)\n",
        "\n",
        "# Load dataset from the hub\n",
        "dataset = load_dataset(\"eltorio/ROCOv2-radiology\", split=\"test\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i8PuqI9Dz64O"
      },
      "id": "i8PuqI9Dz64O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Process the datset"
      ],
      "metadata": {
        "id": "75pMrCVm3pIG"
      },
      "id": "75pMrCVm3pIG"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Image as HFImage\n",
        "dataset = dataset.cast_column(\"image\", HFImage(decode=False))\n",
        "\n",
        "# Processed Dataset\n",
        "processed_ds = dataset.map(\n",
        "    lambda b: preprocess.format_batch(b, cui_mapping, defaults),\n",
        "    batched=True,\n",
        "    batch_size=1024,\n",
        ")"
      ],
      "metadata": {
        "id": "vb59Wjds30VN"
      },
      "id": "vb59Wjds30VN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "Rbjq66Dv9MiA"
      },
      "id": "Rbjq66Dv9MiA"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face model id\n",
        "model_id = \"google/gemma-3-4b-pt\" # or `google/gemma-3-12b-pt`, `google/gemma-3-27-pt`\n",
        "# Check if GPU benefits from bfloat16\n",
        "if torch.cuda.get_device_capability()[0] < 8:\n",
        "    raise ValueError(\"GPU does not support bfloat16, please use a GPU that supports bfloat16.\")\n",
        "# Define model init arguments\n",
        "model_kwargs = dict(\n",
        "    attn_implementation=\"eager\", # Use \"flash_attention_2\" when running on Ampere or newer GPU\n",
        "    torch_dtype=torch.bfloat16, # What torch dtype to use, defaults to auto\n",
        "    device_map=\"auto\", # Let torch decide how to load the model\n",
        ")\n",
        "# BitsAndBytesConfig int-4 config\n",
        "model_kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=model_kwargs[\"torch_dtype\"],\n",
        "    bnb_4bit_quant_storage=model_kwargs[\"torch_dtype\"],\n",
        ")\n",
        "# Load model and processor\n",
        "model = AutoModelForImageTextToText.from_pretrained(model_id, **model_kwargs)\n",
        "processor = AutoProcessor.from_pretrained(\"google/gemma-3-4b-it\")"
      ],
      "metadata": {
        "id": "noyzU11cISp3",
        "collapsed": true
      },
      "id": "noyzU11cISp3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Special CUI Tokens\n",
        "tokenizer = processor.tokenizer\n",
        "cui_tokens = [f\"<{cui}>\" for cui in cui_mapping.keys()]\n",
        "num_added = tokenizer.add_tokens(cui_tokens)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "processor.tokenizer = tokenizer"
      ],
      "metadata": {
        "id": "hWezxJbYHwnO"
      },
      "id": "hWezxJbYHwnO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    r=16,\n",
        "    bias=\"none\",\n",
        "    target_modules=\"all-linear\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    modules_to_save=[\n",
        "        \"lm_head\",\n",
        "        \"embed_tokens\",\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "A6Xd5g9tQfsb"
      },
      "id": "A6Xd5g9tQfsb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image as PILImage\n",
        "import io\n",
        "\n",
        "def load_pil(img):\n",
        "    \"\"\"\n",
        "    Handles:\n",
        "    - HF Image with decode=False -> dict with {path, bytes}\n",
        "    - Already-decoded PIL images\n",
        "    \"\"\"\n",
        "    if isinstance(img, dict):\n",
        "        if img.get(\"bytes\") is not None:\n",
        "            return PILImage.open(io.BytesIO(img[\"bytes\"])).convert(\"RGB\")\n",
        "        if img.get(\"path\"):\n",
        "            return PILImage.open(img[\"path\"]).convert(\"RGB\")\n",
        "        raise ValueError(\"Image dict missing both 'bytes' and 'path'.\")\n",
        "\n",
        "    if hasattr(img, \"convert\"):\n",
        "        return img.convert(\"RGB\")\n",
        "\n",
        "    raise ValueError(f\"Unsupported image type: {type(img)}\")\n",
        "\n",
        "\n",
        "def collate_fn(examples):\n",
        "    texts = []\n",
        "    images = []\n",
        "\n",
        "    for example in examples:\n",
        "        # Build text from messages (which contains the image placeholder)\n",
        "        text = processor.apply_chat_template(\n",
        "            example[\"messages\"],\n",
        "            add_generation_prompt=False,\n",
        "            tokenize=False\n",
        "        )\n",
        "        texts.append(text.strip())\n",
        "\n",
        "        # IMPORTANT: pull real image from the column, not from messages\n",
        "        images.append(load_pil(example[\"image\"]))\n",
        "\n",
        "    # Tokenize & process images\n",
        "    batch = processor(\n",
        "        text=texts,\n",
        "        images=images,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True\n",
        "    )\n",
        "\n",
        "    # Labels\n",
        "    labels = batch[\"input_ids\"].clone()\n",
        "\n",
        "    # Mask padding\n",
        "    pad_id = processor.tokenizer.pad_token_id\n",
        "    if pad_id is not None:\n",
        "        labels[labels == pad_id] = -100\n",
        "\n",
        "    # Mask image special tokens (safer handling)\n",
        "    boi_token = processor.tokenizer.special_tokens_map.get(\"boi_token\", None)\n",
        "    if boi_token is not None:\n",
        "        boi_id = processor.tokenizer.convert_tokens_to_ids(boi_token)\n",
        "        labels[labels == boi_id] = -100\n",
        "\n",
        "    # Keep your known extra image token id mask (if it is correct in your setup)\n",
        "    labels[labels == 262144] = -100\n",
        "\n",
        "    batch[\"labels\"] = labels\n",
        "    return batch"
      ],
      "metadata": {
        "id": "gO3yBiVL_9I2"
      },
      "id": "gO3yBiVL_9I2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig\n",
        "args = SFTConfig(\n",
        "    output_dir=\"gemma-product-description\",     # directory to save and repository id\n",
        "    num_train_epochs=1,                         # number of training epochs\n",
        "    per_device_train_batch_size=1,              # batch size per device during training\n",
        "    gradient_accumulation_steps=4,              # number of steps before performing a backward/update pass\n",
        "    gradient_checkpointing=False,                # use gradient checkpointing to save memory\n",
        "    optim=\"adamw_torch_fused\",                  # use fused adamw optimizer\n",
        "    logging_steps=50,                            # log every 5 steps\n",
        "    save_strategy=\"epoch\",                      # save checkpoint every epoch\n",
        "    learning_rate=2e-4,                         # learning rate, based on QLoRA paper\n",
        "    bf16=True,                                  # use bfloat16 precision\n",
        "    max_grad_norm=0.3,                          # max gradient norm based on QLoRA paper\n",
        "    warmup_ratio=0.03,                          # warmup ratio based on QLoRA paper\n",
        "    lr_scheduler_type=\"constant\",               # use constant learning rate scheduler\n",
        "    push_to_hub=True,                           # push model to hub\n",
        "    report_to=\"tensorboard\",                    # report metrics to tensorboard\n",
        "    gradient_checkpointing_kwargs={\n",
        "        \"use_reentrant\": False\n",
        "    },  # use reentrant checkpointing\n",
        "    dataset_text_field=\"\",                      # need a dummy field for collator\n",
        "    dataset_kwargs={\"skip_prepare_dataset\": True},  # important for collator\n",
        ")\n",
        "args.remove_unused_columns = False # important for collator"
      ],
      "metadata": {
        "id": "-706X_xBQmWd"
      },
      "id": "-706X_xBQmWd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "from trl import SFTTrainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=processed_ds,\n",
        "    peft_config=peft_config,\n",
        "    processing_class=processor,\n",
        "    data_collator=collate_fn,\n",
        ")\n",
        "# Start training, the model will be automatically saved to the Hub and the output directory\n",
        "trainer.train()\n",
        "trainer.save_model(\"gemma-3-cui-finetuned-sample1\")  # saves into this directory"
      ],
      "metadata": {
        "id": "F364ZWZpRF1O"
      },
      "id": "F364ZWZpRF1O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# free the memory again\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "DmKg87wAR7_I"
      },
      "id": "DmKg87wAR7_I",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}