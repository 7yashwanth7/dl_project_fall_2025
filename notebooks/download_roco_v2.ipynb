{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download ROCOv2 locally\n",
    "\n",
    "Notebook to pull ROCOv2 to local storage. It uses a hosted mirror by default because the official `roco` script on Hugging Face requires you to manually place the dataset files. You can switch to the official loader if you already downloaded the data.\n",
    "\n",
    "Defaults store data under `./data/roco_v2`. Adjust paths as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deps (pin to avoid ABI mismatches on Colab)\n",
    "!pip install -q --upgrade torch torchvision torchaudio transformers==4.42.3 accelerate peft bitsandbytes \\\n",
    "    numpy==1.26.4 pandas==2.2.2 datasets==2.19.1 pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and dataset choice\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, DownloadConfig\n",
    "from datasets.exceptions import EmptyDatasetError\n",
    "\n",
    "# Where to store\n",
    "BASE_DIR = Path('./data/roco_v2').resolve()\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('Saving to', BASE_DIR)\n",
    "\n",
    "# Choose dataset source\n",
    "# Option 1 (default): hosted mirror that includes images\n",
    "DATASET_NAME = 'flaviagiammarino/roco-dataset'\n",
    "DATASET_CONFIG = None\n",
    "\n",
    "# Option 2: official script (requires you to download ROCO locally first)\n",
    "# DATASET_NAME = 'roco'\n",
    "# DATASET_CONFIG = 'en'\n",
    "\n",
    "# Subset for quick tests; set to None to download all\n",
    "TRAIN_SPLIT = 'train[:100]'  # or None\n",
    "VAL_SPLIT = 'validation[:20]'  # or None\n",
    "TEST_SPLIT = None  # e.g., 'test[:20]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download\n",
    "try:\n",
    "    raw_ds = load_dataset(\n",
    "        DATASET_NAME,\n",
    "        DATASET_CONFIG,\n",
    "        cache_dir=str(BASE_DIR),\n",
    "        download_config=DownloadConfig(use_auth_token=True),\n",
    "    )\n",
    "except EmptyDatasetError as e:\n",
    "    raise RuntimeError(\n",
    "        'Official ROCO loader needs local files. Place them under BASE_DIR and set DATASET_NAME=\"roco\"; '\n",
    "        'or use a mirror that bundles images.'\n",
    "    ) from e\n",
    "\n",
    "splits = {}\n",
    "splits['train'] = raw_ds[TRAIN_SPLIT] if TRAIN_SPLIT else raw_ds['train']\n",
    "splits['validation'] = raw_ds[VAL_SPLIT] if VAL_SPLIT else raw_ds.get('validation', None)\n",
    "splits['test'] = raw_ds[TEST_SPLIT] if TEST_SPLIT else raw_ds.get('test', None)\n",
    "\n",
    "print({k: v.num_rows if v is not None else 0 for k, v in splits.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk in Arrow format (restorable with datasets.load_from_disk)\n",
    "from datasets import DatasetDict\n",
    "\n",
    "to_save = {k: v for k, v in splits.items() if v is not None}\n",
    "ds_to_save = DatasetDict(to_save)\n",
    "out_path = BASE_DIR / 'arrow'\n",
    "out_path.mkdir(parents=True, exist_ok=True)\n",
    "ds_to_save.save_to_disk(out_path)\n",
    "print('Saved to', out_path)\n",
    "print(ds_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: export images + captions to simple folders/CSV for inspection\n",
    "import csv\n",
    "\n",
    "export_dir = BASE_DIR / 'export'\n",
    "img_dir = export_dir / 'images'\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cap_key = None\n",
    "sample_cols = splits['train'].column_names\n",
    "for candidate in ['caption', 'text', 'caption_en', 'description']:\n",
    "    if candidate in sample_cols:\n",
    "        cap_key = candidate\n",
    "        break\n",
    "if cap_key is None:\n",
    "    raise ValueError('Could not find a caption column; please set cap_key manually.')\n",
    "\n",
    "csv_path = export_dir / 'captions.csv'\n",
    "with open(csv_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['split', 'index', 'image_path', 'caption'])\n",
    "    for split_name, ds in to_save.items():\n",
    "        for idx, ex in enumerate(ds):\n",
    "            pil_img = ex['image']\n",
    "            img_path = img_dir / f\"{split_name}_{idx}.jpg\"\n",
    "            pil_img.save(img_path)\n",
    "            writer.writerow([split_name, idx, str(img_path), ex[cap_key]])\n",
    "\n",
    "print('Exported images to', img_dir)\n",
    "print('Captions CSV:', csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visual sanity check on one sample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample = splits['train'][0]\n",
    "plt.imshow(sample['image'])\n",
    "plt.axis('off')\n",
    "plt.title(sample.get(cap_key, ''))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
