{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen2-VL-7B ImageCLEF 2025 Fine-tuning\n",
    "Use shared utilities to load, quantize, and fine-tune the model for ImageCLEF 2025 medical image captioning/concept detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import ModelConfig, QuantizationConfig, FinetuneConfig\n",
    "from src.models.loader import load_multimodal_model\n",
    "from src.models.quantization import quantize_model\n",
    "from src.training.finetune import fine_tune_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure model + training\n",
    "Update `dataset_path` to your ImageCLEF 2025 train split in JSONL format with columns: `image_path`, `instruction`, `output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = ModelConfig(\n",
    "    model_name_or_path=\"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    trust_remote_code=True,\n",
    "    use_flash_attention_2=False,\n",
    ")\n",
    "\n",
    "quant_cfg = QuantizationConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_compute_dtype=\"bfloat16\",\n",
    "    bnb_quant_type=\"nf4\",\n",
    "    use_double_quant=True,\n",
    ")\n",
    "\n",
    "finetune_cfg = FinetuneConfig(\n",
    "    dataset_path=\"data/imageclef_2025_train.jsonl\",\n",
    "    output_dir=\"outputs/qwen2vl-imageclef-2025\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"],\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, processor = load_multimodal_model(model_cfg, quant_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = quantize_model(model, quant_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = fine_tune_model(\n",
    "    quantized_model,\n",
    "    processor,\n",
    "    finetune_cfg,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
