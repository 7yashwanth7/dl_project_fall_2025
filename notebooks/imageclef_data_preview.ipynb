{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageCLEF 2025 Data Prep & Preview\n",
    "\n",
    "Download (if available) and preview ImageCLEF 2025 medical image captioning data. Set `IMAGECLEF_2025_URL` to a private/authenticated ZIP link containing `captioning.jsonl`, `concept_detection.jsonl`, `explainability.jsonl`, and the referenced images. If files already exist locally, no download is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import maybe_download_imageclef_2025, load_imageclef_2025_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/yashwanth/Documents/OMSCS/Deep_Learning/dl_project_fall_2025/data/imageclef_2025\n",
      "IMAGECLEF_2025_URL set: False\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ImageCLEF 2025 data not found. Place captioning.jsonl, concept_detection.jsonl, and explainability.jsonl under the data directory, or set IMAGECLEF_2025_URL to an authenticated download link (e.g., a private ZIP) before running.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMAGECLEF_2025_URL set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mbool\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMAGECLEF_2025_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Download if missing; otherwise returns immediately.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmaybe_download_imageclef_2025\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/OMSCS/Deep_Learning/dl_project_fall_2025/src/data/dataset.py:78\u001b[0m, in \u001b[0;36mmaybe_download_imageclef_2025\u001b[0;34m(data_dir, url_env_var)\u001b[0m\n\u001b[1;32m     76\u001b[0m url \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(url_env_var)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImageCLEF 2025 data not found. Place captioning.jsonl, concept_detection.jsonl, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand explainability.jsonl under the data directory, or set IMAGECLEF_2025_URL \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto an authenticated download link (e.g., a private ZIP) before running.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Try to download a ZIP archive from the provided URL.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m zip_path \u001b[38;5;241m=\u001b[39m data_dir_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimageclef_2025.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ImageCLEF 2025 data not found. Place captioning.jsonl, concept_detection.jsonl, and explainability.jsonl under the data directory, or set IMAGECLEF_2025_URL to an authenticated download link (e.g., a private ZIP) before running."
     ]
    }
   ],
   "source": [
    "data_dir = os.path.abspath(\"../data/imageclef_2025\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(\"IMAGECLEF_2025_URL set:\", bool(os.environ.get(\"IMAGECLEF_2025_URL\")))\n",
    "\n",
    "# Download if missing; otherwise returns immediately.\n",
    "maybe_download_imageclef_2025(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = load_imageclef_2025_splits(data_dir)\n",
    "caption_ds = splits[\"captioning\"]\n",
    "concept_ds = splits[\"concept_detection\"]\n",
    "explain_ds = splits[\"explainability\"]\n",
    "\n",
    "print(caption_ds)\n",
    "print(concept_ds)\n",
    "print(explain_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "if len(caption_ds) == 0:\n",
    "    raise ValueError(\"Captioning dataset is empty; ensure JSONL has records.\")\n",
    "\n",
    "idx = random.randint(0, len(caption_ds) - 1)\n",
    "sample = caption_ds[idx]\n",
    "print(f\"Sample #{idx}\")\n",
    "print(\"Instruction:\", sample.get(\"instruction\"))\n",
    "print(\"Output:\", sample.get(\"output\"))\n",
    "print(\"Image path:\", sample.get(\"image_path\"))\n",
    "\n",
    "img = Image.open(sample[\"image_path\"]).convert(\"RGB\")\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load ROCOv2 from Hugging Face\n",
    "dataset = load_dataset(\"eltorio/ROCOv2-radiology\")\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "print(len(train_ds))  # ~60k examples (HF split)\n",
    "\n",
    "# 2. Inspect one training example\n",
    "example = train_ds[0]\n",
    "\n",
    "print(\"Image ID:\", example[\"image_id\"])\n",
    "print(\"Caption :\", example[\"caption\"])\n",
    "print(\"CUIs    :\", example[\"cui\"])\n",
    "\n",
    "# 3. Show the image\n",
    "img = example[\"image\"]  # this is already a PIL.Image\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
